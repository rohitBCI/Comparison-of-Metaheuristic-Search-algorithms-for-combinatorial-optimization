{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adaptive-tulsa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import copy\n",
    "import pandas as pd\n",
    "import operator\n",
    "from collections import defaultdict\n",
    "np.set_printoptions(suppress=True)\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "continental-proxy",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "    def __init__(self, data = None, next_node = None, prev_node = None):\n",
    "        self.data = data\n",
    "        self.next_node =  next_node\n",
    "        self.prev_node = prev_node\n",
    "\n",
    "class DoublyLinkedList(object):\n",
    "    def __init__(self, head = None):\n",
    "        self.head = head\n",
    "    \n",
    "    def traverse(self):\n",
    "        current_node = self.head\n",
    "        while current_node != None:\n",
    "            print(current_node.data)\n",
    "            current_node = current_node.next_node\n",
    "    \n",
    "    def get_size(self):\n",
    "        count = 0\n",
    "        current_node = self.head\n",
    "        while current_node != None:\n",
    "            count += 1\n",
    "            current_node = current_node.next_node\n",
    "        return count\n",
    "            \n",
    "    def append(self, data):\n",
    "        new_node = Node(data)\n",
    "        current_node = self.head\n",
    "        new_node.next_node = current_node\n",
    "        new_node.prev_node = None\n",
    "        if current_node != None:\n",
    "            current_node.prev_node = new_node\n",
    "        self.head = new_node\n",
    "    \n",
    "    def insert_end(self, data):\n",
    "        new_node = Node(data)\n",
    "        new_node.next = None\n",
    "        if self.head == None:\n",
    "            new_node.prev_node = None\n",
    "            self.head = new_node\n",
    "        return\n",
    "    \n",
    "        first_node = self.head\n",
    "        while first_node.next_node:\n",
    "            first_node = first_node.next_node\n",
    "        first_node.next_node = new_node\n",
    "        new_node.prev_node = first_node\n",
    "    \n",
    "    \n",
    "    def delete(self, data):\n",
    "        current_node = self.head\n",
    "        while current_node != None:\n",
    "            if current_node.data == data and current_node == self.head:\n",
    "                if not current_node.next_node:\n",
    "                    current_node = None\n",
    "                    self.head = None\n",
    "                    return\n",
    "                else:\n",
    "                    q = current_node.next_node\n",
    "                    current_node.next_node = None\n",
    "                    q.prev_node = None\n",
    "                    current_node = None\n",
    "                    self.head = q\n",
    "                    return\n",
    "            \n",
    "            elif current_node.data == data:\n",
    "                #print(\"hello\")\n",
    "                if current_node.next_node != None:\n",
    "                    p = current_node.prev_node\n",
    "                    q = current_node.next_node\n",
    "                    p.next_node = q\n",
    "                    q.prev_node = p\n",
    "                    current_node.next_node = None\n",
    "                    current_node.prev_node = None\n",
    "                    current_node = None\n",
    "                    return\n",
    "                else:\n",
    "                    #print(\"bye\")\n",
    "                    p = current_node.prev_node\n",
    "                    p.next_node = None\n",
    "                    current_node.prev_node = None\n",
    "                    current = None\n",
    "                    return\n",
    "            current_node =  current_node.next_node\n",
    "    \n",
    "class Bucket(object):\n",
    "    def __init__(self, value):\n",
    "        self.data = DoublyLinkedList()\n",
    "\n",
    "class Bucket_Arrays(object):\n",
    "    def __init__(self, maxdegree):\n",
    "        self.bucket_range = maxdegree\n",
    "        self.left_buckets = np.array([Bucket(i) for i in range(-self.bucket_range,self.bucket_range+1)])\n",
    "        self.right_buckets = np.array([Bucket(i) for i in range(-self.bucket_range,self.bucket_range+1)])\n",
    "        self.max_gain_left = -maxdegree\n",
    "        self.max_gain_right = -maxdegree\n",
    "        self.left_size = 0\n",
    "        self.right_size = 0\n",
    "        self.fixed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "unlimited-rachel",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_num_cuts(df):\n",
    "    connected_edges = df[df['Partition']==0]['ID connected vertices'].values\n",
    "    outside_partition = list(df[df['Partition']==1].index)\n",
    "    connected_edges = [item in outside_partition for sublist in connected_edges for item in sublist]\n",
    "    num_cuts = np.sum(connected_edges)\n",
    "    return num_cuts\n",
    "\n",
    "def initialize_gain_buckets(df, buckets):\n",
    "    max_degree = 16\n",
    "    for i in range(len(df)):\n",
    "        connected_edges = df['ID connected vertices'][i]\n",
    "        partition_value = df['Partition'][i]\n",
    "        gain = 0\n",
    "        for j in connected_edges:\n",
    "            connected_partition = df['Partition'][j]\n",
    "            if(partition_value != connected_partition):\n",
    "                gain += 1\n",
    "            else:\n",
    "                gain -= 1\n",
    "        df.loc[i,'Gain'] = gain\n",
    "        \n",
    "        if partition_value == 0:\n",
    "            buckets.left_buckets[gain+max_degree].data.append(i)\n",
    "            buckets.left_size += 1\n",
    "            if(buckets.max_gain_left < gain):\n",
    "                buckets.max_gain_left = gain\n",
    "        else:\n",
    "            buckets.right_buckets[gain+max_degree].data.append(i)\n",
    "            buckets.right_size += 1\n",
    "            if(buckets.max_gain_right < gain):\n",
    "                buckets.max_gain_right = gain\n",
    "    return df,buckets\n",
    "\n",
    "###\n",
    "def update_df_buckets(df,buckets,vertex_max_gain, gain_update,max_degree):\n",
    "\n",
    "    partition_value = df.loc[vertex_max_gain,'Partition']\n",
    "    df.loc[vertex_max_gain,'Partition'] = int(not(partition_value))\n",
    "    if df.loc[vertex_max_gain,'Partition'] == 1:\n",
    "        buckets.left_buckets[gain_update+max_degree].data.delete(vertex_max_gain)\n",
    "        buckets.left_size -= 1\n",
    "        while(buckets.left_buckets[buckets.max_gain_left+max_degree].data.head == None and buckets.max_gain_left>-max_degree):\n",
    "            buckets.max_gain_left -= 1\n",
    "        df,buckets = re_calculate_gain(df, buckets,vertex_max_gain,max_degree,1)\n",
    "        \n",
    "    else:\n",
    "        buckets.right_buckets[gain_update+max_degree].data.delete(vertex_max_gain)\n",
    "        buckets.right_size -= 1\n",
    "        while(buckets.right_buckets[buckets.max_gain_right+max_degree].data.head == None and buckets.max_gain_right>-max_degree):\n",
    "            buckets.max_gain_right -= 1\n",
    "        df,buckets = re_calculate_gain(df, buckets,vertex_max_gain,max_degree,0)\n",
    "    return df, buckets\n",
    "\n",
    "def re_calculate_gain(df, buckets, vertex_max_gain, max_degree, changed_partition):\n",
    "    vertices_to_update = df.loc[vertex_max_gain]['ID connected vertices']\n",
    "    for i in vertices_to_update:\n",
    "        if(df.loc[i]['Fixed'] == 0):\n",
    "            current_gain = df.loc[i]['Gain']\n",
    "            current_partition = df.iloc[i]['Partition']\n",
    "            if current_partition == 1:\n",
    "                buckets.right_buckets[current_gain+max_degree].data.delete(i)\n",
    "                buckets.right_size -= 1\n",
    "                while(buckets.right_buckets[buckets.max_gain_right+max_degree].data.head == None and buckets.max_gain_right>-max_degree):\n",
    "                    buckets.max_gain_right -= 1\n",
    "            else:\n",
    "                buckets.left_buckets[current_gain+max_degree].data.delete(i)\n",
    "                buckets.left_size -= 1\n",
    "                while(buckets.left_buckets[buckets.max_gain_left+max_degree].data.head == None and buckets.max_gain_left>-max_degree):\n",
    "                    buckets.max_gain_left -= 1\n",
    "        \n",
    "            partition_value = df['Partition'][i]\n",
    "            if (partition_value == changed_partition):\n",
    "                new_gain = current_gain - 2\n",
    "            else:\n",
    "                new_gain = current_gain + 2\n",
    "            df.loc[i,'Gain'] = new_gain\n",
    "            if(partition_value == 1): \n",
    "                buckets.right_buckets[new_gain+max_degree].data.append(i)\n",
    "                buckets.right_size += 1\n",
    "                if(buckets.max_gain_right < new_gain):\n",
    "                    buckets.max_gain_right = new_gain\n",
    "            else:\n",
    "                buckets.left_buckets[new_gain+max_degree].data.append(i)\n",
    "                buckets.left_size += 1\n",
    "                if(buckets.max_gain_left < new_gain):\n",
    "                    buckets.max_gain_left = new_gain\n",
    "    df.loc[vertex_max_gain,'Fixed'] = 1\n",
    "    buckets.fixed += 1\n",
    "    #df.loc[vertex_max_gain,'Gain'] = -999\n",
    "    return df, buckets\n",
    "\n",
    "def initialise_data(partitioning):\n",
    "    # Loading the single planar graph of 500 vertices\n",
    "    data = defaultdict(list)\n",
    "    for line in open(\"Graph500.txt\"):\n",
    "        split_line=line.split()\n",
    "        ID_vertex = int(split_line[0])\n",
    "        num_connected_vertices  = int(split_line[2])\n",
    "        ID_connected_vertices = [int(i)-1 for i in split_line[3:]]\n",
    "        if (ID_vertex) not in data.keys():\n",
    "            data[ID_vertex].append(0)\n",
    "            data[ID_vertex].append(0)\n",
    "            data[ID_vertex].append(ID_connected_vertices)\n",
    "            data[ID_vertex].append(0)\n",
    "    data_frame = pd.DataFrame(data.values(),columns = ['Gain', 'Fixed','ID connected vertices', 'Partition'])\n",
    "\n",
    "    num_vertices = len(data_frame)\n",
    "    if(partitioning is None):\n",
    "        partition = random.sample(range(0,num_vertices),250)\n",
    "        data_frame.loc[partition,'Partition'] = 1\n",
    "    else:\n",
    "        data_frame[\"Partition\"] = partitioning\n",
    "    return data_frame\n",
    "\n",
    "def FM_one_pass(df, current_num_cuts):\n",
    "    num_cuts = current_num_cuts\n",
    "    num_vertices = 500\n",
    "    min_cuts = num_cuts\n",
    "    max_degree = 16\n",
    "    buckets = Bucket_Arrays(max_degree)\n",
    "    df,buckets = initialize_gain_buckets(df, buckets)\n",
    "    save_partition = copy.deepcopy(df['Partition'].values)\n",
    "    while(buckets.fixed < num_vertices):\n",
    "        if(buckets.left_size >= buckets.right_size):\n",
    "            gain_update = buckets.max_gain_left\n",
    "            vertex_max_gain = buckets.left_buckets[gain_update+max_degree].data.head.data\n",
    "            df, buckets = update_df_buckets(df,buckets,vertex_max_gain,gain_update,max_degree)\n",
    "            \n",
    "        else:\n",
    "            gain_update = buckets.max_gain_right\n",
    "            vertex_max_gain = buckets.right_buckets[gain_update+max_degree].data.head.data\n",
    "            df, buckets = update_df_buckets(df,buckets,vertex_max_gain,gain_update,max_degree)\n",
    "            \n",
    "        num_cuts = num_cuts - gain_update\n",
    "        #print(num_cuts)\n",
    "        if(num_cuts < min_cuts and buckets.left_size == buckets.right_size):\n",
    "            save_partition = copy.deepcopy(df['Partition'].values)\n",
    "            min_cuts = num_cuts\n",
    "    return min_cuts, save_partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "quantitative-external",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLS_one_run(max_passes):\n",
    "    flag = 0\n",
    "    total_passes = 0\n",
    "    total_time = 0\n",
    "    best_local_optimum = math.inf\n",
    "    mls_local_optimum = math.inf\n",
    "    optimal_partition = None\n",
    "    run_data_frame = pd.DataFrame(columns = ['Coverged local optima','Time(s)'])\n",
    "    while(True):\n",
    "        df = initialise_data(optimal_partition)\n",
    "        current_num_cuts = calculate_num_cuts(df)\n",
    "        start = time.time()\n",
    "        local_optimum, optimal_partition = FM_one_pass(df,current_num_cuts)\n",
    "        total_passes += 1\n",
    "        \n",
    "        if(local_optimum < best_local_optimum and total_passes <= max_passes):\n",
    "            best_local_optimum = local_optimum\n",
    "            flag = 0\n",
    "        else:\n",
    "            end = time.time()\n",
    "            elpased_time = end - start\n",
    "            if(total_passes <= max_passes):\n",
    "                optimal_partition = None\n",
    "                if(mls_local_optimum > best_local_optimum): #less\n",
    "                    mls_local_optimum = best_local_optimum\n",
    "                best_local_optimum = math.inf\n",
    "                flag = 0\n",
    "            else:\n",
    "                flag = 1\n",
    "            observations= [mls_local_optimum,elpased_time]\n",
    "            run_data_frame.loc[len(run_data_frame)] = observations\n",
    "        if(flag == 1):\n",
    "            break\n",
    "        print(total_passes, end='\\r')\n",
    "    return run_data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "independent-contemporary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run  0\n",
      "Run  1\n",
      "Run  2\n",
      "Run  3\n",
      "Run  4\n",
      "Run  5\n",
      "Run  6\n",
      "Run  7\n",
      "Run  8\n",
      "Run  9\n",
      "Run  10\n",
      "Run  11\n",
      "Run  12\n",
      "Run  13\n",
      "Run  14\n",
      "Run  15\n",
      "Run  16\n",
      "Run  17\n",
      "Run  18\n",
      "Run  19\n",
      "Run  20\n",
      "Run  21\n",
      "Run  22\n",
      "Run  23\n",
      "Run  24\n",
      "1000\r"
     ]
    }
   ],
   "source": [
    "# MLS\n",
    "max_passes = 1000\n",
    "total_runs = 25\n",
    "mls_run_data_frame = pd.DataFrame(columns = ['Coverged local optima','Time(s)'])\n",
    "for i in range(0,25):\n",
    "    print(\"Run \",i)\n",
    "    observations = MLS_one_run(max_passes)\n",
    "    mls_observations = [observations.min()[0],observations.sum()[1]]\n",
    "    mls_run_data_frame.loc[len(mls_run_data_frame)] = mls_observations\n",
    "#run_data_frame.to_csv(r'FM_baseline.csv', index = False)\n",
    "#np.savetxt(r'FM_baseline_median.txt', run_data_frame.median(), fmt='%f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "rotary-hammer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coverged local optima</th>\n",
       "      <th>Time(s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.0</td>\n",
       "      <td>380.599131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.0</td>\n",
       "      <td>383.575606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.0</td>\n",
       "      <td>357.934232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.0</td>\n",
       "      <td>354.655026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.0</td>\n",
       "      <td>353.516454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14.0</td>\n",
       "      <td>354.553613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12.0</td>\n",
       "      <td>359.054485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9.0</td>\n",
       "      <td>354.258965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13.0</td>\n",
       "      <td>355.836990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>13.0</td>\n",
       "      <td>353.742008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12.0</td>\n",
       "      <td>359.583275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13.0</td>\n",
       "      <td>354.131436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10.0</td>\n",
       "      <td>352.875257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13.0</td>\n",
       "      <td>360.202858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>12.0</td>\n",
       "      <td>355.455267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15.0</td>\n",
       "      <td>353.184662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18.0</td>\n",
       "      <td>366.040343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8.0</td>\n",
       "      <td>355.617169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>11.0</td>\n",
       "      <td>363.213441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>8.0</td>\n",
       "      <td>372.675135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>8.0</td>\n",
       "      <td>367.791726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>14.0</td>\n",
       "      <td>386.191190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>13.0</td>\n",
       "      <td>419.192467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>14.0</td>\n",
       "      <td>382.678062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>17.0</td>\n",
       "      <td>470.967028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Coverged local optima     Time(s)\n",
       "0                     8.0  380.599131\n",
       "1                    10.0  383.575606\n",
       "2                    14.0  357.934232\n",
       "3                    12.0  354.655026\n",
       "4                    13.0  353.516454\n",
       "5                    14.0  354.553613\n",
       "6                    12.0  359.054485\n",
       "7                     9.0  354.258965\n",
       "8                    13.0  355.836990\n",
       "9                    13.0  353.742008\n",
       "10                   12.0  359.583275\n",
       "11                   13.0  354.131436\n",
       "12                   10.0  352.875257\n",
       "13                   13.0  360.202858\n",
       "14                   12.0  355.455267\n",
       "15                   15.0  353.184662\n",
       "16                   18.0  366.040343\n",
       "17                    8.0  355.617169\n",
       "18                   11.0  363.213441\n",
       "19                    8.0  372.675135\n",
       "20                    8.0  367.791726\n",
       "21                   14.0  386.191190\n",
       "22                   13.0  419.192467\n",
       "23                   14.0  382.678062\n",
       "24                   17.0  470.967028"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mls_run_data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "vital-brown",
   "metadata": {},
   "outputs": [],
   "source": [
    "mls_run_data_frame.to_csv(r'MLS_min_25.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unexpected-agriculture",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
