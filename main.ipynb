{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "instrumental-temple",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import pandas as pd\n",
    "import operator\n",
    "from collections import defaultdict\n",
    "np.set_printoptions(suppress=True)\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "complex-cycling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create doubly-linked list data structure\n",
    "class Node(object):\n",
    "    # Singly linked node\n",
    "    def __init__(self, value=None, next=None, prev=None):\n",
    "        self.value = value\n",
    "        self.next = next\n",
    "        self.prev = prev\n",
    "\n",
    "class doubly_linked_list(object):\n",
    "    def __init__(self):\n",
    "        self.head = None\n",
    "        self.tail = None\n",
    "        self.count = 0\n",
    "\n",
    "    def append_item(self, value):\n",
    "        # Append an item \n",
    "        new_item = Node(value, None, None)\n",
    "        if self.head is None:\n",
    "            self.head = new_item\n",
    "            self.tail = self.head\n",
    "        else:\n",
    "            new_item.prev = self.tail\n",
    "            self.tail.next = new_item\n",
    "            self.tail = new_item\n",
    "        self.count += 1\n",
    "    \n",
    "    def iter(self):\n",
    "        # Iterate the list\n",
    "        current = self.head\n",
    "        while current:\n",
    "            item_val = current.value\n",
    "            current = current.next\n",
    "            yield item_val\n",
    "\n",
    "    def print_forward(self):\n",
    "        for node in self.iter():\n",
    "            print(node)   \n",
    "        \n",
    "    def search_item(self, val):\n",
    "         for node in self.iter():\n",
    "            if val == node:\n",
    "                return True\n",
    "            return False\n",
    "     \n",
    "    def delete(self, value):\n",
    "        # Delete a specific item\n",
    "        current = self.head\n",
    "        node_deleted = False\n",
    "        if current is None:\n",
    "            node_deleted = False\n",
    "\n",
    "        elif current.value == value:\n",
    "            self.head = current.next\n",
    "            if(self.head is not None):\n",
    "                self.head.prev = None\n",
    "            node_deleted = True\n",
    "\n",
    "        elif self.tail.value == value:\n",
    "            self.tail = self.tail.prev\n",
    "            self.tail.next = None\n",
    "            node_deleted = True\n",
    "\n",
    "        else:\n",
    "            while current:\n",
    "                if current.value == value:\n",
    "                    current.prev.next = current.next\n",
    "                    current.next.prev = current.prev\n",
    "                    node_deleted = True\n",
    "                current = current.next\n",
    "\n",
    "        if node_deleted:\n",
    "            self.count -= 1\n",
    "    \n",
    "    def is_empty(self):\n",
    "        if self.head is None:\n",
    "            return True\n",
    "        else:\n",
    "            current = self.head\n",
    "            return current.value\n",
    "\n",
    "# Initialize left and right bucket\n",
    "def initialize_buckets(Partition_A,Partition_B,left_bucket,right_bucket):\n",
    "    gain_array = np.array([])\n",
    "    for i in Partition_A:\n",
    "        gain = 0\n",
    "        connected_array = df.iloc[i-1][1]\n",
    "        for j in connected_array:\n",
    "            if int(j) in Partition_A:\n",
    "                gain -= 1\n",
    "            else:\n",
    "                gain += 1\n",
    "        gain_array = np.append(gain_array,gain)\n",
    "        left_bucket[int(gain)].append_item(i)\n",
    "        \n",
    "    gain_array = np.array([])\n",
    "    for i in Partition_B:\n",
    "        gain = 0\n",
    "        connected_array = df.iloc[i-1][1]\n",
    "        for j in connected_array:\n",
    "            if int(j) in Partition_B:\n",
    "                gain -= 1\n",
    "            else:\n",
    "                gain += 1\n",
    "        gain_array = np.append(gain_array,gain)\n",
    "        right_bucket[int(gain)].append_item(i)\n",
    "    return left_bucket, right_bucket\n",
    "\n",
    "# Find vertex with maximum gain in buckets\n",
    "def calculate_max_gain(buckets, max_degree):\n",
    "    for i in range(max_degree,-max_degree-1,-1):\n",
    "        if(buckets[i].is_empty()!=True):\n",
    "            vertex_max_gain = buckets[i].is_empty()\n",
    "            gain = i\n",
    "            return int(vertex_max_gain), gain\n",
    "        \n",
    "# Calculate number of cuts\n",
    "def calculate_num_cuts(Partition_A,Partition_B):\n",
    "    cuts = 0\n",
    "    edges = 0\n",
    "    for i in Partition_A:\n",
    "        connected_array = df.iloc[i-1][1]\n",
    "        for j in connected_array:\n",
    "            if int(j) not in Partition_A:\n",
    "                cuts += 1\n",
    "            edges += 1 \n",
    "            \n",
    "    for i in Partition_B:\n",
    "        connected_array = df.iloc[i-1][1]\n",
    "        for j in connected_array:\n",
    "            if int(j) not in Partition_B:\n",
    "                cuts += 1\n",
    "            edges += 1 \n",
    "    return cuts, edges\n",
    "\n",
    "# Update buckets after vertex move \n",
    "def update_buckets(buckets_to_update,buckets, vertex):\n",
    "    bucket = defaultdict()\n",
    "    for i in buckets:\n",
    "        bucket[i] = doubly_linked_list()\n",
    "    gain_array = np.array([])\n",
    "    for i in buckets_to_update:\n",
    "        gain = 0\n",
    "        connected_array = df.iloc[i-1][1]\n",
    "        for j in connected_array:\n",
    "            if int(j) in buckets_to_update:\n",
    "                gain -= 1\n",
    "            else:\n",
    "                gain += 1\n",
    "        gain_array = np.append(gain_array,gain)\n",
    "        if i is not vertex:\n",
    "            bucket[int(gain)].append_item(i)\n",
    "    return bucket\n",
    "\n",
    "# Fiduccia Mattheyses algorithm for local search\n",
    "def Fiduccia_Mattheyses_LS():\n",
    "    start = time.time()\n",
    "    # Create a partioning (A,B)\n",
    "    num_vertices = len(df)\n",
    "    vertices = np.array([i for i in range(1,num_vertices+1)])\n",
    "    cut = int(0.5 * num_vertices)\n",
    "    np.random.shuffle(vertices)\n",
    "    Partition_A = vertices[:cut]\n",
    "    Partition_B = vertices[cut:] \n",
    "\n",
    "    cuts_tracker = np.array([]).reshape(0,3)\n",
    "    fixed_vertices = []\n",
    "\n",
    "    # Create left and right gain buckets\n",
    "    max_degree = np.max(df['Number of connected vertices'])\n",
    "    buckets = np.array([i for i in range(-max_degree,max_degree+1)])\n",
    "    left_bucket = defaultdict()\n",
    "    right_bucket = defaultdict()\n",
    "    for i in buckets:\n",
    "        left_bucket[i] = doubly_linked_list()\n",
    "        right_bucket[i] = doubly_linked_list()\n",
    "\n",
    "    # Initialize buckets and cuts tracker\n",
    "    left_buckets,right_buckets = initialize_buckets(Partition_A,Partition_B,left_bucket,right_bucket)\n",
    "\n",
    "    cuts, _ = calculate_num_cuts(Partition_A,Partition_B)\n",
    "    state = np.array([cuts,Partition_A,Partition_B])\n",
    "    cuts_tracker = np.vstack((cuts_tracker,state))\n",
    "    \n",
    "    while(len(fixed_vertices)<num_vertices):\n",
    "        if(len(Partition_A)>=len(Partition_B)):\n",
    "            # Calculate vertex with maximum gain\n",
    "            vertex_max_gain,gain = calculate_max_gain(left_buckets,max_degree)\n",
    "\n",
    "            # Update buckets and partitions\n",
    "            left_buckets[gain].delete(vertex_max_gain)\n",
    "            Partition_A = np.delete(Partition_A, np.where(Partition_A == vertex_max_gain))\n",
    "            Partition_B = np.append(Partition_B,vertex_max_gain)\n",
    "            right_buckets = update_buckets(Partition_B, buckets, vertex_max_gain)\n",
    "\n",
    "            # Update fixed vertices and cuts tracker\n",
    "            fixed_vertices.append(vertex_max_gain)\n",
    "            cuts, _ = calculate_num_cuts(Partition_A,Partition_B)\n",
    "            state = np.array([cuts,Partition_A,Partition_B])\n",
    "            cuts_tracker = np.vstack((cuts_tracker,state))\n",
    "\n",
    "        else:\n",
    "            # Calculate vertex with maximum gain\n",
    "            vertex_max_gain,gain = calculate_max_gain(right_buckets,max_degree)\n",
    "\n",
    "            # Update buckets and partitions\n",
    "            right_buckets[gain].delete(vertex_max_gain)\n",
    "            Partition_B = np.delete(Partition_B, np.where(Partition_B == vertex_max_gain))\n",
    "            Partition_A = np.append(Partition_A,vertex_max_gain)\n",
    "            left_buckets = update_buckets(Partition_A, buckets,vertex_max_gain)\n",
    "\n",
    "            # Update fixed vertices and cuts tracker\n",
    "            fixed_vertices.append(vertex_max_gain)\n",
    "            cuts, _ = calculate_num_cuts(Partition_A,Partition_B)\n",
    "            state = np.array([cuts,Partition_A,Partition_B])\n",
    "            cuts_tracker = np.vstack((cuts_tracker,state))\n",
    "        print(len(fixed_vertices),end='\\r')\n",
    "    \n",
    "    optimal_num_cuts = np.argmin(cuts_tracker[:,0]) \n",
    "    final_partition1 = cuts_tracker[optimal_num_cuts][1]\n",
    "    final_partition2 = cuts_tracker[optimal_num_cuts][2]\n",
    "    end = time.time()\n",
    "    elapsed_time = end-start\n",
    "    print(\"Time taken\", elapsed_time)\n",
    "    return [optimal_num_cuts,final_partition1,final_partition2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "considered-smell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the single planar graph of 500 vertices\n",
    "data = defaultdict(list)\n",
    "for line in open(\"Graph500.txt\"):\n",
    "    split_line=line.split()\n",
    "    ID_vertex = split_line[0]\n",
    "    num_connected_vertices  = split_line[2]\n",
    "    ID_connected_vertices = split_line[3:]\n",
    "    if (ID_vertex) not in data.keys():\n",
    "        data[ID_vertex].append(int(num_connected_vertices))\n",
    "        data[ID_vertex].append(ID_connected_vertices)\n",
    "df = pd.DataFrame(data.values(),columns = ['Number of connected vertices','ID connected vertices'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "complicated-sympathy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken 61.89481997489929\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[202,\n",
       " array([413, 364, 456,  35, 122, 109, 412,  71, 344, 312, 304, 386, 177,\n",
       "         43, 192, 426, 491, 288, 475, 280, 406, 273,  20, 129, 214,  72,\n",
       "        455, 294, 275, 446,  74, 120, 148, 310, 402, 237, 410, 308,  50,\n",
       "        153, 156,  15, 114,  54, 137, 460, 284, 281, 329, 375, 159, 423,\n",
       "         93, 485,  30,  48, 243, 443, 371, 317, 144, 188, 444, 113, 474,\n",
       "        361, 436,  51, 141,  73, 154, 107, 396, 218, 345, 483, 145,  21,\n",
       "        151, 205,  91, 459,  33, 461,  99, 115, 219, 112, 362,  95, 223,\n",
       "         22, 194, 416, 388, 497, 471, 228, 404, 405, 353, 339, 146,  81,\n",
       "        351, 453, 385, 191, 185,  42, 382, 163,  98,  39, 230, 216, 327,\n",
       "        490,  68,  18, 181, 278, 499, 487, 376, 162, 252, 492, 407, 138,\n",
       "         14,  75, 133,  62, 132, 283, 253, 337, 372, 445,   1, 226, 500,\n",
       "        468, 495, 260,  84, 383, 176, 477,  16, 201,  70,  52, 231, 254,\n",
       "        448, 251, 244,  83, 392, 307, 305,  28, 189, 103, 267, 359, 370,\n",
       "        106, 101, 174, 245, 178, 210, 470, 155, 207,  82, 282, 236,  87,\n",
       "          5, 450,  36, 204, 421, 248, 360, 233, 320, 341,  27,  77, 458,\n",
       "        241, 250, 263, 415, 394, 384, 365, 131,  38,  26, 400, 211, 358,\n",
       "         13, 309, 130,  49, 313, 266, 393,  55, 190, 167, 296, 286, 140,\n",
       "         41, 433,  67,  31, 126, 331,  61, 429, 463,  58, 142, 299, 187,\n",
       "        391, 473,  96, 322, 292, 357,  92, 102, 269, 160, 104, 379, 213,\n",
       "        125, 169, 290]),\n",
       " array([395, 165,  23, 489,  80, 272,  24, 336, 486,  86, 348, 164, 300,\n",
       "        488, 293, 170, 229, 117, 247, 127, 369,  59, 498,  29, 314, 442,\n",
       "        301, 152, 173, 268,  65, 193, 255, 139,  25, 289, 287, 323, 225,\n",
       "         10, 116, 121, 172, 451, 424, 199,  85,  60,  17,  11, 277, 196,\n",
       "        326, 264, 347, 200, 464, 118,   8, 343, 422, 150, 484,  79, 316,\n",
       "        387, 232, 325, 332, 480, 476, 432, 220, 472,  66, 124,   7, 438,\n",
       "        209, 123, 276, 258, 262, 425, 274, 403, 434, 346,  34,  45,  56,\n",
       "        465, 437, 356, 342,  69,   2, 374, 466, 235,  12, 340, 128, 212,\n",
       "        355, 202, 265, 428, 315, 298, 367, 390, 171, 206,   3, 203, 186,\n",
       "        318, 481, 161, 417, 482, 180,  64, 494, 242, 158, 349,  53,  46,\n",
       "        330, 270, 430, 271, 136, 291,  32, 215, 380, 279, 478, 217, 350,\n",
       "        302, 457, 111, 208, 363, 143, 398, 377, 397, 411, 234, 449, 198,\n",
       "         63, 493, 249, 135, 435, 389, 311, 238, 452, 297, 427,  78, 328,\n",
       "         88, 222,  47,  40, 409, 334, 157, 324, 224, 419,  97, 440, 441,\n",
       "        184, 408, 240, 447, 227, 100,  90, 179, 306, 479, 166, 414,  57,\n",
       "        399,   4,  44, 257,   6, 496, 246, 373, 469,  89, 221, 195, 149,\n",
       "        381, 352, 454, 197, 303, 335, 183, 182, 295, 108,  94, 105, 401,\n",
       "        168,  19, 439, 354, 110, 261,  76, 239,   9, 462, 256, 134, 319,\n",
       "        338, 119, 420, 467, 321, 175, 366, 368, 431,  37, 285, 378, 147,\n",
       "        418, 333, 259])]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fiduccia_Mattheyses_LS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "following-dealing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
