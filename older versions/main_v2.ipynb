{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "rolled-relationship",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import pandas as pd\n",
    "import operator\n",
    "from collections import defaultdict\n",
    "np.set_printoptions(suppress=True)\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "arctic-prime",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "    def __init__(self, data = None, next_node = None, prev_node = None):\n",
    "        self.data = data\n",
    "        self.next_node =  next_node\n",
    "        self.prev_node = prev_node\n",
    "\n",
    "class DoublyLinkedList(object):\n",
    "    def __init__(self, head = None):\n",
    "        self.head = head\n",
    "    \n",
    "    def traverse(self):\n",
    "        current_node = self.head\n",
    "        while current_node != None:\n",
    "            print(current_node.data)\n",
    "            current_node = current_node.next_node\n",
    "    \n",
    "    def get_size(self):\n",
    "        count = 0\n",
    "        current_node = self.head\n",
    "        while current_node != None:\n",
    "            count += 1\n",
    "            current_node = current_node.next_node\n",
    "        return count\n",
    "            \n",
    "    def append(self, data):\n",
    "        new_node = Node(data)\n",
    "        current_node = self.head\n",
    "        new_node.next_node = current_node\n",
    "        new_node.prev_node = None\n",
    "        if current_node != None:\n",
    "            current_node.prev_node = new_node\n",
    "        self.head = new_node\n",
    "    \n",
    "    def insert_end(self, data):\n",
    "        new_node = Node(data)\n",
    "        new_node.next = None\n",
    "        if self.head == None:\n",
    "            new_node.prev_node = None\n",
    "            self.head = new_node\n",
    "        return\n",
    "    \n",
    "        first_node = self.head\n",
    "        while first_node.next_node:\n",
    "            first_node = first_node.next_node\n",
    "        first_node.next_node = new_node\n",
    "        new_node.prev_node = first_node\n",
    "    \n",
    "    \n",
    "    def delete(self, data):\n",
    "        current_node = self.head\n",
    "        while current_node != None:\n",
    "            if current_node.data == data and current_node == self.head:\n",
    "                if not current_node.next_node:\n",
    "                    current_node = None\n",
    "                    self.head = None\n",
    "                    return\n",
    "                else:\n",
    "                    q = current_node.next_node\n",
    "                    current_node.next_node = None\n",
    "                    q.prev_node = None\n",
    "                    current_node = None\n",
    "                    self.head = q\n",
    "                    return\n",
    "            \n",
    "            elif current_node.data == data:\n",
    "                if current_node.next_node != None:\n",
    "                    p = current_node.prev_node\n",
    "                    q = current_node.next_node\n",
    "                    p.next_node = q\n",
    "                    q.prev_node = p\n",
    "                    current_node.next_node = None\n",
    "                    current_node.prev_node = None\n",
    "                    current_node = None\n",
    "                    return\n",
    "                else:\n",
    "                    p = current_node.prev_node\n",
    "                    p.next_node = None\n",
    "                    current_node.prev_node = None\n",
    "                    current = None\n",
    "                    return\n",
    "            current_node =  current_node.next_node\n",
    "\n",
    "class Bucket(object):\n",
    "    def __init__(self, value):\n",
    "        self.gain = value\n",
    "        self.data = DoublyLinkedList()\n",
    "\n",
    "class Bucket_Arrays(object):\n",
    "    def __init__(self, maxdegree):\n",
    "        self.bucket_range = maxdegree\n",
    "        self.left_buckets = [Bucket(i) for i in range(-self.bucket_range,self.bucket_range+1)]\n",
    "        self.right_buckets = [Bucket(i) for i in range(-self.bucket_range,self.bucket_range+1)]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "collect-threat",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_num_cuts(Partition_A,Partition_B):\n",
    "    cuts = 0\n",
    "    for i in Partition_A:\n",
    "        connected_array = df.iloc[int(i)-1][3]\n",
    "        for j in connected_array:\n",
    "            if int(j) not in Partition_A:\n",
    "                cuts += 1\n",
    "    return cuts\n",
    "\n",
    "def initialize_buckets(Partition_A,Partition_B,max_degree):\n",
    "    bucket_arrays = Bucket_Arrays(max_degree)\n",
    "    for i in Partition_A:\n",
    "        gain = 0\n",
    "        connected_array = df.iloc[int(i)-1][3]\n",
    "        for j in connected_array:\n",
    "            if int(j) in Partition_A:\n",
    "                gain -= 1\n",
    "            else:\n",
    "                gain += 1\n",
    "        df.loc[int(i)-1,'Gain'] = gain\n",
    "        bucket_arrays.left_buckets[gain+max_degree].data.append(i)\n",
    "    \n",
    "    for i in Partition_B:\n",
    "        gain = 0\n",
    "        connected_array = df.iloc[int(i)-1][3]\n",
    "        for j in connected_array:\n",
    "            if int(j) in Partition_B:\n",
    "                gain -= 1\n",
    "            else:\n",
    "                gain += 1\n",
    "        df.loc[int(i)-1,'Gain'] = gain\n",
    "        bucket_arrays.right_buckets[gain+max_degree].data.append(i)\n",
    "    return bucket_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "interstate-blackberry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find vertex with maximum gain in buckets\n",
    "def calculate_vertex_max_gain(buckets):\n",
    "    for bucket in buckets:\n",
    "        max_gain_bucket = bucket.data.head\n",
    "        if(max_gain_bucket != None):\n",
    "            max_gain = bucket.gain\n",
    "            vertex_max_gain = max_gain_bucket.data\n",
    "    return max_gain, vertex_max_gain\n",
    "\n",
    "def re_calculate_gain(connected_array,Partition,buckets):\n",
    "    for i in connected_array:\n",
    "        for k in buckets:\n",
    "            k.data.delete(int(i))\n",
    "    for i in connected_array:\n",
    "        gain = 0\n",
    "        adjacent_vertices = df.iloc[int(i)-1][3]\n",
    "        for j in adjacent_vertices:\n",
    "            if int(j) in Partition:\n",
    "                gain -= 1\n",
    "            else:\n",
    "                gain += 1\n",
    "        buckets[gain+max_degree].data.append(i)\n",
    "    return buckets\n",
    "\n",
    "# Update buckets after vertex move \n",
    "def update_buckets(buckets, max_gain,vertex_max_gain, update_gain_left, Partition_A,Partition_B):\n",
    "    vertex_max_gain = int(vertex_max_gain)\n",
    "    if(update_gain_left == 0):\n",
    "        buckets.left_buckets[max_gain+max_degree].data.delete(vertex_max_gain)\n",
    "        connected_array = df.iloc[vertex_max_gain-1][3]\n",
    "        buckets.right_buckets = re_calculate_gain(connected_array,Partition_B, buckets.right_buckets)\n",
    "        \n",
    "    else:\n",
    "        buckets.right_buckets[max_gain+max_degree].data.delete(vertex_max_gain)\n",
    "        connected_array = df.iloc[vertex_max_gain-1][3]\n",
    "        buckets.left_buckets = re_calculate_gain(connected_array,Partition_A, buckets.left_buckets)\n",
    "    return buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "friendly-edgar",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Fiduccia_Mattheyses_LS():\n",
    "    start = time.time()\n",
    "    \n",
    "    # Create two partitions A and B\n",
    "    num_vertices = len(df)\n",
    "    vertices = np.arange(1,501)\n",
    "    np.random.shuffle(vertices)\n",
    "    cut = int(0.5 * num_vertices)\n",
    "    Partition_A = vertices[:cut]\n",
    "    Partition_B = vertices[cut:]\n",
    "\n",
    "    max_degree = np.max(df['Number of connected vertices'])\n",
    "    num_cuts = calculate_num_cuts(Partition_A,Partition_B)\n",
    "    min_cuts = num_cuts\n",
    "    buckets = initialize_buckets(Partition_A,Partition_B,max_degree)\n",
    "    \n",
    "    while(np.sum(df['Fixed'])<num_vertices):\n",
    "        if(len(Partition_A)>=len(Partition_B)):\n",
    "            # Calculate vertex with maximum gain in left bucket\n",
    "            max_gain, vertex_max_gain = calculate_vertex_max_gain(buckets.left_buckets)\n",
    "\n",
    "            # Update buckets and partitions\n",
    "            Partition_A = np.delete(Partition_A, np.where(Partition_A == vertex_max_gain))\n",
    "            Partition_B = np.append(Partition_B,vertex_max_gain)\n",
    "\n",
    "            buckets = update_buckets(buckets, max_gain,vertex_max_gain,0, Partition_A, Partition_B)\n",
    "\n",
    "            # Update fixed vertices and cuts tracker\n",
    "            fixed_vertices.append(vertex_max_gain)\n",
    "            cuts = calculate_num_cuts(Partition_A,Partition_B)\n",
    "            if(cuts < min_cuts):\n",
    "                save_state = np.array([cuts,Partition_A,Partition_B])\n",
    "                min_cuts = cuts\n",
    "\n",
    "        else:\n",
    "\n",
    "            # Calculate vertex with maximum gain in left bucket\n",
    "            max_gain, vertex_max_gain = calculate_vertex_max_gain(buckets.right_buckets)\n",
    "\n",
    "            # Update buckets and partitions\n",
    "            Partition_B = np.delete(Partition_B, np.where(Partition_B == vertex_max_gain))\n",
    "            Partition_A = np.append(Partition_A,vertex_max_gain)\n",
    "\n",
    "            buckets = update_buckets(buckets, max_gain,vertex_max_gain,1, Partition_A, Partition_B)\n",
    "\n",
    "            # Update fixed vertices and cuts tracker\n",
    "            fixed_vertices.append(vertex_max_gain)\n",
    "            cuts = calculate_num_cuts(Partition_A,Partition_B)\n",
    "            if(cuts < min_cuts):\n",
    "                save_state = np.array([cuts,Partition_A,Partition_B])\n",
    "                min_cuts = cuts\n",
    "        #print(len(fixed_vertices),end='\\r')\n",
    "        print(cuts)\n",
    "    # optimal_num_cuts = np.min(cuts_tracker[:,0]) \n",
    "    # final_partition1 = cuts_tracker[np.argmin(cuts_tracker[:,0]) ][1]\n",
    "    # final_partition2 = cuts_tracker[np.argmin(cuts_tracker[:,0]) ][2]\n",
    "    end = time.time()\n",
    "    elapsed_time = end-start\n",
    "    print(\"Time taken\", elapsed_time)\n",
    "    return save_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "perceived-casting",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_vertices = len(df)\n",
    "vertices = np.arange(1,5)\n",
    "np.random.shuffle(vertices)\n",
    "cut = int(0.5 * num_vertices)\n",
    "Partition_A = vertices[:cut]\n",
    "Partition_B = vertices[cut:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "invalid-edgar",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_degree = np.max(df['Number of connected vertices'])\n",
    "num_cuts = calculate_num_cuts(Partition_A,Partition_B)\n",
    "min_cuts = num_cuts\n",
    "buckets = initialize_buckets(Partition_A,Partition_B,max_degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "express-tumor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "#buckets.right_buckets[4].data.traverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "functional-zimbabwe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#buckets.right_buckets[2].data.traverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "talented-stocks",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "innocent-moldova",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_gain, vertex_max_gain = calculate_vertex_max_gain(buckets.left_buckets)\n",
    "Partition_A = np.delete(Partition_A, np.where(Partition_A == vertex_max_gain))\n",
    "Partition_B = np.append(Partition_B,vertex_max_gain)\n",
    "buckets = update_buckets(buckets, max_gain,vertex_max_gain,0, Partition_A, Partition_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diverse-accommodation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "rough-bridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "buckets.left_buckets[4].data.traverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "racial-mandate",
   "metadata": {},
   "outputs": [],
   "source": [
    "buckets.right_buckets[4].data.traverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twenty-sector",
   "metadata": {},
   "outputs": [],
   "source": [
    "if(len(Partition_A)>=len(Partition_B)):\n",
    "    # Calculate vertex with maximum gain in left bucket\n",
    "    max_gain, vertex_max_gain = calculate_vertex_max_gain(buckets.left_buckets)\n",
    "\n",
    "    # Update buckets and partitions\n",
    "    Partition_A = np.delete(Partition_A, np.where(Partition_A == vertex_max_gain))\n",
    "    Partition_B = np.append(Partition_B,vertex_max_gain)\n",
    "\n",
    "    buckets = update_buckets(buckets, max_gain,vertex_max_gain,0, Partition_A, Partition_B)\n",
    "\n",
    "    # Update fixed vertices and cuts tracker\n",
    "    fixed_vertices.append(vertex_max_gain)\n",
    "    cuts = calculate_num_cuts(Partition_A,Partition_B)\n",
    "    if(cuts < min_cuts):\n",
    "        save_state = np.array([cuts,Partition_A,Partition_B])\n",
    "        min_cuts = cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "according-speaker",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dramatic-egypt",
   "metadata": {},
   "outputs": [],
   "source": [
    "while(np.sum(df['Fixed'])<num_vertices):\n",
    "    if(len(Partition_A)>=len(Partition_B)):\n",
    "        # Calculate vertex with maximum gain in left bucket\n",
    "        max_gain, vertex_max_gain = calculate_vertex_max_gain(buckets.left_buckets)\n",
    "\n",
    "        # Update buckets and partitions\n",
    "        Partition_A = np.delete(Partition_A, np.where(Partition_A == vertex_max_gain))\n",
    "        Partition_B = np.append(Partition_B,vertex_max_gain)\n",
    "\n",
    "        buckets = update_buckets(buckets, max_gain,vertex_max_gain,0, Partition_A, Partition_B)\n",
    "\n",
    "        # Update fixed vertices and cuts tracker\n",
    "        fixed_vertices.append(vertex_max_gain)\n",
    "        cuts = calculate_num_cuts(Partition_A,Partition_B)\n",
    "        if(cuts < min_cuts):\n",
    "            save_state = np.array([cuts,Partition_A,Partition_B])\n",
    "            min_cuts = cuts\n",
    "\n",
    "    else:\n",
    "\n",
    "        # Calculate vertex with maximum gain in left bucket\n",
    "        max_gain, vertex_max_gain = calculate_vertex_max_gain(buckets.right_buckets)\n",
    "\n",
    "        # Update buckets and partitions\n",
    "        Partition_B = np.delete(Partition_B, np.where(Partition_B == vertex_max_gain))\n",
    "        Partition_A = np.append(Partition_A,vertex_max_gain)\n",
    "\n",
    "        buckets = update_buckets(buckets, max_gain,vertex_max_gain,1, Partition_A, Partition_B)\n",
    "\n",
    "        # Update fixed vertices and cuts tracker\n",
    "        fixed_vertices.append(vertex_max_gain)\n",
    "        cuts = calculate_num_cuts(Partition_A,Partition_B)\n",
    "        if(cuts < min_cuts):\n",
    "            save_state = np.array([cuts,Partition_A,Partition_B])\n",
    "            min_cuts = cuts\n",
    "    #print(len(fixed_vertices),end='\\r')\n",
    "    print(cuts)\n",
    "# optimal_num_cuts = np.min(cuts_tracker[:,0]) \n",
    "# final_partition1 = cuts_tracker[np.argmin(cuts_tracker[:,0]) ][1]\n",
    "# final_partition2 = cuts_tracker[np.argmin(cuts_tracker[:,0]) ][2]\n",
    "end = time.time()\n",
    "elapsed_time = end-start\n",
    "print(\"Time taken\", elapsed_time)\n",
    "return save_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unavailable-tournament",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "continuing-motivation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the single planar graph of 500 vertices\n",
    "data = defaultdict(list)\n",
    "for line in open(\"Graph501.txt\"):\n",
    "    split_line=line.split()\n",
    "    ID_vertex = split_line[0]\n",
    "    num_connected_vertices  = split_line[2]\n",
    "    ID_connected_vertices = split_line[3:]\n",
    "    if (ID_vertex) not in data.keys():\n",
    "        data[ID_vertex].append(int(num_connected_vertices))\n",
    "        data[ID_vertex].append(0)\n",
    "        data[ID_vertex].append(0)\n",
    "        data[ID_vertex].append(ID_connected_vertices)\n",
    "        data[ID_vertex].append(0)\n",
    "df = pd.DataFrame(data.values(),columns = ['Number of connected vertices','Gain', 'Fixed','ID connected vertices', 'Partition'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "unlimited-cleveland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of connected vertices</th>\n",
       "      <th>Gain</th>\n",
       "      <th>Fixed</th>\n",
       "      <th>ID connected vertices</th>\n",
       "      <th>Partition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[2]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 3]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[2, 4]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[3]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number of connected vertices  Gain  Fixed ID connected vertices  Partition\n",
       "0                             1     0      0                   [2]          0\n",
       "1                             2     0      0                [1, 3]          0\n",
       "2                             2     0      0                [2, 4]          0\n",
       "3                             1     0      0                   [3]          0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "south-scale",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "looking-cooperation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time elapsed before while 0.12070393562316895\n",
      "time for one loop 0.04688692092895508\n",
      "649\n",
      "time for one loop 0.03839397430419922\n",
      "643\n",
      "time for one loop 0.037897348403930664\n",
      "638\n",
      "time for one loop 0.0359041690826416\n",
      "632\n",
      "time for one loop 0.034906625747680664\n",
      "627\n",
      "time for one loop 0.04089045524597168\n",
      "622\n",
      "time for one loop 0.04088997840881348\n",
      "617\n",
      "time for one loop 0.04089069366455078\n",
      "610\n",
      "time for one loop 0.03889608383178711\n",
      "605\n",
      "time for one loop 0.03789854049682617\n",
      "600\n",
      "time for one loop 0.034906625747680664\n",
      "595\n",
      "time for one loop 0.03688406944274902\n",
      "590\n",
      "time for one loop 0.034906625747680664\n",
      "585\n",
      "time for one loop 0.0359039306640625\n",
      "578\n",
      "time for one loop 0.036900997161865234\n",
      "571\n",
      "time for one loop 0.042885541915893555\n",
      "566\n",
      "time for one loop 0.03889608383178711\n",
      "562\n",
      "time for one loop 0.0359041690826416\n",
      "555\n",
      "time for one loop 0.0359036922454834\n",
      "551\n",
      "time for one loop 0.0359039306640625\n",
      "545\n",
      "time for one loop 0.03490638732910156\n",
      "539\n",
      "time for one loop 0.03690195083618164\n",
      "535\n",
      "time for one loop 0.03792738914489746\n",
      "529\n",
      "time for one loop 0.03989267349243164\n",
      "525\n",
      "time for one loop 0.04485154151916504\n",
      "521\n",
      "time for one loop 0.036901235580444336\n",
      "517\n",
      "time for one loop 0.03593254089355469\n",
      "514\n",
      "time for one loop 0.037869930267333984\n",
      "510\n",
      "time for one loop 0.036901235580444336\n",
      "507\n",
      "time for one loop 0.04188847541809082\n",
      "503\n",
      "time for one loop 0.04288530349731445\n",
      "498\n",
      "time for one loop 0.04288434982299805\n",
      "492\n",
      "time for one loop 0.04188847541809082\n",
      "489\n",
      "time for one loop 0.048058271408081055\n",
      "485\n",
      "time for one loop 0.045844078063964844\n",
      "482\n",
      "time for one loop 0.041887521743774414\n",
      "478\n",
      "time for one loop 0.04790544509887695\n",
      "475\n",
      "time for one loop 0.04985761642456055\n",
      "471\n",
      "time for one loop 0.048845529556274414\n",
      "468\n",
      "time for one loop 0.04686379432678223\n",
      "460\n",
      "time for one loop 0.04590868949890137\n",
      "455\n",
      "time for one loop 0.041886329650878906\n",
      "447\n",
      "time for one loop 0.03889298439025879\n",
      "444\n",
      "time for one loop 0.03889632225036621\n",
      "436\n",
      "time for one loop 0.04089689254760742\n",
      "434\n",
      "time for one loop 0.041886091232299805\n",
      "422\n",
      "time for one loop 0.03789401054382324\n",
      "420\n",
      "time for one loop 0.04286789894104004\n",
      "416\n",
      "time for one loop 0.04388308525085449\n",
      "414\n",
      "time for one loop 0.052884817123413086\n",
      "1350\n",
      "time for one loop 0.04789924621582031\n",
      "1358\n",
      "time for one loop 0.04787182807922363\n",
      "1346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rohit\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:47: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "C:\\Users\\Rohit\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:18: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "C:\\Users\\Rohit\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:6: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time for one loop 0.04787254333496094\n",
      "1357\n",
      "time for one loop 0.05083799362182617\n",
      "1368\n",
      "time for one loop 0.0638277530670166\n",
      "1368\n",
      "time for one loop 0.07082939147949219\n",
      "1379\n",
      "time for one loop 0.05583930015563965\n",
      "1379\n",
      "time for one loop 0.051885366439819336\n",
      "1390\n",
      "time for one loop 0.0608057975769043\n",
      "1390\n",
      "time for one loop 0.06136059761047363\n",
      "1401\n",
      "time for one loop 0.056847333908081055\n",
      "1401\n",
      "time for one loop 0.05086398124694824\n",
      "1412\n",
      "time for one loop 0.05285930633544922\n",
      "1412\n",
      "time for one loop 0.06283187866210938\n",
      "1423\n",
      "time for one loop 0.05186176300048828\n",
      "1423\n",
      "time for one loop 0.05684804916381836\n",
      "1434\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-77c7c98866fe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFiduccia_Mattheyses_LS\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-42-50e992a90315>\u001b[0m in \u001b[0;36mFiduccia_Mattheyses_LS\u001b[1;34m()\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[1;31m# Update fixed vertices and cuts tracker\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m             \u001b[0mfixed_vertices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvertex_max_gain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m             \u001b[0mcuts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalculate_num_cuts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPartition_A\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mPartition_B\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m             \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcuts\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mmin_cuts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m                 \u001b[0msave_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcuts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mPartition_A\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mPartition_B\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-26-32cab6884dca>\u001b[0m in \u001b[0;36mcalculate_num_cuts\u001b[1;34m(Partition_A, Partition_B)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mcuts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mPartition_A\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0mconnected_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mconnected_array\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mPartition_A\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1501\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1503\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1504\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1505\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_slice_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslice_obj\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_ixs\u001b[1;34m(self, i, axis)\u001b[0m\n\u001b[0;32m   2953\u001b[0m                 \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2954\u001b[0m                 \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2955\u001b[1;33m                 \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnew_values\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2956\u001b[0m             )\n\u001b[0;32m   2957\u001b[0m             \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_is_copy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[0;32m    335\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_cast_failure\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 337\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSingleBlockManager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    338\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m         \u001b[0mgeneric\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNDFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mfrom_array\u001b[1;34m(cls, array, index)\u001b[0m\n\u001b[0;32m   1580\u001b[0m         \u001b[0mConstructor\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mwe\u001b[0m \u001b[0mhave\u001b[0m \u001b[0man\u001b[0m \u001b[0marray\u001b[0m \u001b[0mthat\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0myet\u001b[0m \u001b[0ma\u001b[0m \u001b[0mBlock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1581\u001b[0m         \"\"\"\n\u001b[1;32m-> 1582\u001b[1;33m         \u001b[0mblock\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_block\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1583\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36mmake_block\u001b[1;34m(values, placement, klass, ndim, dtype)\u001b[0m\n\u001b[0;32m   2723\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mklass\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2724\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2725\u001b[1;33m         \u001b[0mklass\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_block_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2726\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2727\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mklass\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mDatetimeTZBlock\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36mget_block_type\u001b[1;34m(values, dtype)\u001b[0m\n\u001b[0;32m   2681\u001b[0m         \u001b[1;31m# Need this first(ish) so that Sparse[datetime] is sparse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2682\u001b[0m         \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExtensionBlock\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2683\u001b[1;33m     \u001b[1;32melif\u001b[0m \u001b[0mis_categorical_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2684\u001b[0m         \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCategoricalBlock\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2685\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\dtypes\\common.py\u001b[0m in \u001b[0;36mis_categorical_dtype\u001b[1;34m(arr_or_dtype)\u001b[0m\n\u001b[0;32m    562\u001b[0m     \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m     \"\"\"\n\u001b[1;32m--> 564\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExtensionDtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    565\u001b[0m         \u001b[1;31m# GH#33400 fastpath for dtype object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0marr_or_dtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"category\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fin = Fiduccia_Mattheyses_LS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "editorial-hebrew",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
